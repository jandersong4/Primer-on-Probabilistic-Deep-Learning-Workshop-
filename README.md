# Probabilistic Deep Learning Workshop

Este repositório contém material prático inspirado no workshop **Primer on Probabilistic Deep Learning**, apresentado no YouTube. (link: https://www.youtube.com/watch?v=ZK3NjrGLIQY)

## Objetivo

Fornecer uma introdução prática às técnicas de **Probabilistic Deep Learning**, demonstrando como estender modelos de aprendizado profundo para estimar **incertezas** nas previsões, além de outputs determinísticos.

## Conteúdo

- **Distribuições estatísticas básicas**: Revisão de conceitos fundamentais em probabilidade, como distribuição normal, entropia e KL-divergência.  
- **Regressão probabilística**: Construção de modelos lineares no estilo probabilístico usando TensorFlow Probability.  
- **Redes neurais convolucionais probabilísticas (CNNs)**:  
  - Comparação entre **modelos determinísticos** e **probabilísticos**.  
  - Avaliação de **treinamento e inferência** em datasets como MNIST e MNIST-C (versão corrompida).  
  - Cálculo de **entropia** para quantificar a incerteza das previsões.  

## Por que probabilístico?

Modelos probabilísticos vão além de apenas prever classes ou valores: eles oferecem **confiança** por meio de métricas como entropia ou intervalos de credibilidade. Isso é essencial em aplicações onde saber *o que o modelo não sabe* pode ser tão importante quanto a previsão em si.

## Referência

Este conteúdo foi baseado no workshop **Primer on Probabilistic Deep Learning (Workshop)** disponível no YouTube: **[assista aqui](https://www.youtube.com/watch?v=ZK3NjrGLIQY&t=4586s)**. Agradeço aos autores por compartilhar esse material didático.
